{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea53b0f-0f64-4eda-9ad6-00336c252618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58dd90-ba01-43f2-8dbf-14674b8229d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"VENDOR_MASTER.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e940714-1f39-44e9-99a0-9b5798a7dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols_to_fix = [\n",
    "    'BDOs and BU SPLIT_AS ',\n",
    "    'BDOs and BU SPLIT_EPS',\n",
    "    'BDOs and BU SPLIT_SPS',\n",
    "    'BDOs and BU SPLIT_S&C',\n",
    "    'BDOs and BU SPLIT_Other',\n",
    "    'TOTAL_Weight NSB Total',\n",
    "    'TOTAL_Gross Margin',\n",
    "    'ADVANCED SOLUTIONS_Weight NSB BU',\n",
    "    'ADVANCED SOLUTIONS_Weight NSB Total',\n",
    "    'ADVANCED SOLUTIONS_Gross Margin',\n",
    "    'ENDPOINT SOLUTIONS_Weight NSB BU',\n",
    "    'ENDPOINT SOLUTIONS_Weight NSB Total',\n",
    "    'ENDPOINT SOLUTIONS_Gross Margin',\n",
    "    'MAVERICK_Weight NSB BU',\n",
    "    'MAVERICK_Weight NSB Total',\n",
    "    'MAVERICK_Gross Margin',\n",
    "    'GCC_Weight NSB BU',\n",
    "    'GCC_Weight NSB Total',\n",
    "    'GCC_Gross Margin',\n",
    "    'SCORE'\n",
    "]\n",
    "\n",
    "for col in numeric_cols_to_fix:\n",
    "    if df[col].dtype == 'O':\n",
    "        df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df[numeric_cols_to_fix].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44875f24-6a0b-474a-9bb7-c24ea33e62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "df[int_cols] = df[int_cols].astype('float64')\n",
    "\n",
    "col = 'NET SALES BILLED_NSB/Creation'\n",
    "\n",
    "df[col] = (\n",
    "    df[col]\n",
    "    .astype(str)              \n",
    "    .str.replace(',', '.', regex=False)\n",
    "    .replace('', '0')        \n",
    ")\n",
    "\n",
    "df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "categorical_people = [\n",
    "    'BDOs and BU SPLIT_Silvia',\n",
    "    'BDOs and BU SPLIT_Arnau',\n",
    "    'BDOs and BU SPLIT_Dani',\n",
    "    'BDOs and BU SPLIT_BDOs'\n",
    "]\n",
    "\n",
    "for col in categorical_people:\n",
    "    df[col] = df[col].astype('object')\n",
    "    categorical_people = [\n",
    "    'BDOs and BU SPLIT_Silvia',\n",
    "    'BDOs and BU SPLIT_Arnau',\n",
    "    'BDOs and BU SPLIT_Dani',\n",
    "    'BDOs and BU SPLIT_BDOs'\n",
    "]\n",
    "\n",
    "for col in categorical_people:\n",
    "    df[col] = df[col].astype('object')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(3)\n",
    "\n",
    "df = df.drop(columns=['VENDORS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3824d27-d462-47c5-8e0d-bda4e42f4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['SCORE']\n",
    "X = df.drop(columns=['SCORE'])\n",
    "\n",
    "num_cols = X.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for c in num_cols:\n",
    "    X[f\"{c}_scaled\"] = (X[c] - X[c].mean()) / X[c].std()\n",
    "\n",
    "X = X.drop(columns=num_cols)\n",
    "\n",
    "X.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2fb65-b662-4ffa-9d72-be36267f8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat_nan = [\"BDOs and BU SPLIT_Distribution Model\", \"BDOs and BU SPLIT_Status\"]\n",
    "df[cols_cat_nan] = df[cols_cat_nan].fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472eb61-6b5c-4999-93a1-c8b1ecc46a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TOP VENDORS_TOP Vendors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e5259-1c08-46f4-ae66-7f19d1f81a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TOP VENDORS_LIST\"] = df[\"TOP VENDORS_TOP Vendors\"] \\\n",
    "    .astype(str) \\\n",
    "    .str.split(\",\") \\\n",
    "    .apply(lambda lst: [int(x) for x in lst if x.strip()!=''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a11214-f5c7-4c5d-8c12-8972cebc1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "top_vendor_dummies = pd.DataFrame(\n",
    "    mlb.fit_transform(df[\"TOP VENDORS_LIST\"]),\n",
    "    columns=[f\"TOPV_{v}\" for v in mlb.classes_],\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "df = pd.concat([df.drop(columns=[\"TOP VENDORS_TOP Vendors\", \"TOP VENDORS_LIST\"]), top_vendor_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e0f4b-5520-4488-b723-b977de7152f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e7908-3ec4-4b9b-a9b3-d6b0c0653867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = df.copy()\n",
    "\n",
    "df_pre = pd.get_dummies(df_pre, drop_first=False)\n",
    "\n",
    "y = df_pre[\"SCORE\"]\n",
    "X = df_pre.drop(columns=[\"SCORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65307da1-e9f1-482d-8543-a9c6f19a7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b7bf0-40cb-4f2a-af69-500f71713db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lasso_cv = LassoCV(cv=5, random_state=42, max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "alpha_opt = lasso_cv.alpha_\n",
    "coefs = lasso_cv.coef_\n",
    "\n",
    "print(\"Alpha óptimo:\", alpha_opt)\n",
    "print(\"Número de características no nulas:\", (coefs != 0).sum())\n",
    "\n",
    "y_pred = lasso_cv.predict(X_test)\n",
    "print(\"MSE en test:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R² en test:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bc3f7-f9be-4c37-b65c-ccf76973d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63365505-5c1c-4c51-b01f-af0ec0bad30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"RANDOM FOREST RESULTS\")\n",
    "print(\"MSE:\", mse_rf)\n",
    "print(\"RMSE:\", np.sqrt(mse_rf))\n",
    "print(\"R²:\", r2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566983a-3253-47fc-9b51-ba45c5d29506",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gbr.predict(X_test)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"\\nGRADIENT BOOSTING RESULTS\")\n",
    "print(\"MSE:\", mse_gb)\n",
    "print(\"RMSE:\", np.sqrt(mse_gb))\n",
    "print(\"R²:\", r2_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e7618-383b-48bb-90ae-fded6cecebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GB\n",
    "importances_gb = gbr.feature_importances_\n",
    "indices_gb = np.argsort(importances_gb)[::-1]\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(top_n), importances_gb[indices_gb[:top_n]][::-1])\n",
    "plt.yticks(range(top_n), X_train.columns[indices_gb[:top_n]][::-1])\n",
    "plt.title(\"Top 20 Feature Importances - Gradient Boosting\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#RF\n",
    "importances_rf = rf.feature_importances_\n",
    "indices_rf = np.argsort(importances_rf)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(top_n), importances_rf[indices_rf[:top_n]][::-1])\n",
    "plt.yticks(range(top_n), X_train.columns[indices_rf[:top_n]][::-1])\n",
    "plt.title(\"Top 20 Feature Importances - Random Forest\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911fb6f5-5242-4995-9e42-9b4c215a36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "\n",
    "#Gradient Boosting\n",
    "importances_gb = gbr.feature_importances_\n",
    "indices_gb = np.argsort(importances_gb)[::-1]\n",
    "top_gb_features = X_train.columns[indices_gb[:top_n]]\n",
    "top_gb_values = importances_gb[indices_gb[:top_n]]\n",
    "\n",
    "#Random Forest\n",
    "importances_rf = rf.feature_importances_\n",
    "indices_rf = np.argsort(importances_rf)[::-1]\n",
    "top_rf_features = X_train.columns[indices_rf[:top_n]]\n",
    "top_rf_values = importances_rf[indices_rf[:top_n]]\n",
    "\n",
    "#mètriques del Gradient Boosting\n",
    "mse_gb = mean_squared_error(y_test, gbr.predict(X_test))\n",
    "rmse_gb = np.sqrt(mse_gb)\n",
    "r2_gb = r2_score(y_test, gbr.predict(X_test))\n",
    "\n",
    "#mètriques del Random Forest\n",
    "mse_rf = mean_squared_error(y_test, rf.predict(X_test))\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, rf.predict(X_test))\n",
    "\n",
    "all_top_features = list(set(top_gb_features).union(set(top_rf_features)))\n",
    "\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(all_top_features)))\n",
    "color_map = {feat: colors[i] for i, feat in enumerate(all_top_features)}\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = GridSpec(2, 2, height_ratios=[4, 1])\n",
    "\n",
    "# Gràfic d’importància del Gradient Boosting\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.barh(\n",
    "    top_gb_features[::-1],\n",
    "    top_gb_values[::-1],\n",
    "    color=[color_map[f] for f in top_gb_features[::-1]]\n",
    ")\n",
    "ax1.set_title(\"Top 10 Variables més Importants – Gradient Boosting\")\n",
    "ax1.set_xlabel(\"Importància\")\n",
    "\n",
    "# Gràfic d’importància del Random Forest\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.barh(\n",
    "    top_rf_features[::-1],\n",
    "    top_rf_values[::-1],\n",
    "    color=[color_map[f] for f in top_rf_features[::-1]]\n",
    ")\n",
    "ax2.set_title(\"Top 10 Variables més Importants – Random Forest\")\n",
    "ax2.set_xlabel(\"Importància\")\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax3.axis(\"off\")\n",
    "ax3.text(\n",
    "    0.01,\n",
    "    0.5,\n",
    "    f\"MSE: {mse_gb:.4f}\\nRMSE: {rmse_gb:.4f}\\nR²: {r2_gb:.4f}\",\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax4.axis(\"off\")\n",
    "ax4.text(\n",
    "    0.01,\n",
    "    0.5,\n",
    "    f\"MSE: {mse_rf:.4f}\\nRMSE: {rmse_rf:.4f}\\nR²: {r2_rf:.4f}\",\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe3757-0bd7-434e-bd26-70bb0df2167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_gb_features = X_train.columns[indices_gb[:10]]\n",
    "\n",
    "X_train_top10 = X_train[top_gb_features]\n",
    "X_test_top10 = X_test[top_gb_features]\n",
    "\n",
    "\n",
    "\n",
    "vlasso = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "vlasso.fit(X_train_top10, y_train)\n",
    "\n",
    "y_pred_vlasso = vlasso.predict(X_test_top10)\n",
    "\n",
    "\n",
    "gb_top10 = GradientBoostingRegressor(random_state=42)\n",
    "gb_top10.fit(X_train_top10, y_train)\n",
    "\n",
    "y_pred_gb_top10 = gb_top10.predict(X_test_top10)\n",
    "\n",
    "\n",
    "rf_top10 = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "rf_top10.fit(X_train_top10, y_train)\n",
    "\n",
    "y_pred_rf_top10 = rf_top10.predict(X_test_top10)\n",
    "\n",
    "\n",
    "def mostrar_metrics(nom, y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Resultats de {nom}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\\n\")\n",
    "\n",
    "mostrar_metrics(\"VLasso\", y_test, y_pred_vlasso)\n",
    "mostrar_metrics(\"Gradient Boosting (top10)\", y_test, y_pred_gb_top10)\n",
    "mostrar_metrics(\"Random Forest (top10)\", y_test, y_pred_rf_top10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df6db4-1918-4306-95e7-72be2fc1e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_base = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [2, 3, 4],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=gbr_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Millor combinació d’hiperparàmetres:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"\\nR² en train:\", grid.best_score_)\n",
    "\n",
    "gbr_opt = grid.best_estimator_\n",
    "\n",
    "y_pred_opt = gbr_opt.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_opt = mean_squared_error(y_test, y_pred_opt)\n",
    "rmse_opt = np.sqrt(mse_opt)\n",
    "r2_opt = r2_score(y_test, y_pred_opt)\n",
    "\n",
    "print(\"\\nRESULTATS DEL MODEL OPTIMITZAT\")\n",
    "print(\"MSE:\", mse_opt)\n",
    "print(\"RMSE:\", rmse_opt)\n",
    "print(\"R²:\", r2_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad36a75-d3ca-421f-9b08-3dd26d137f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP 20 MODEL ORIGINAL\n",
    "importances_gb_orig = gbr.feature_importances_\n",
    "indices_gb_orig = np.argsort(importances_gb_orig)[::-1]\n",
    "\n",
    "top20_orig_features = X_train.columns[indices_gb_orig[:20]]\n",
    "top20_orig_values = importances_gb_orig[indices_gb_orig[:20]]\n",
    "\n",
    "print(\"TOP 20 VARIABLES – MODEL ORIGINAL\\n\")\n",
    "for f, v in zip(top20_orig_features, top20_orig_values):\n",
    "    print(f\"{f}: {v}\")\n",
    "\n",
    "# TOP 20 MODEL OPTIMITZAT\n",
    "importances_gb_opt = gbr_opt.feature_importances_\n",
    "indices_gb_opt = np.argsort(importances_gb_opt)[::-1]\n",
    "\n",
    "top20_opt_features = X_train.columns[indices_gb_opt[:20]]\n",
    "top20_opt_values = importances_gb_opt[indices_gb_opt[:20]]\n",
    "\n",
    "print(\"\\nTOP 20 VARIABLES – MODEL OPTIMITZAT\\n\")\n",
    "for f, v in zip(top20_opt_features, top20_opt_values):\n",
    "    print(f\"{f}: {v}\")\n",
    "\n",
    "# COMPARACIÓ ENTRE MODELS\n",
    "set_orig = set(top20_orig_features)\n",
    "set_opt = set(top20_opt_features)\n",
    "\n",
    "comunes = set_orig.intersection(set_opt)\n",
    "nomes_original = set_orig - set_opt\n",
    "nomes_optimitzat = set_opt - set_orig\n",
    "\n",
    "print(\"\\nVARIABLES COMUNES ALS DOS MODELS:\\n\")\n",
    "for x in comunes:\n",
    "    print(x)\n",
    "\n",
    "print(\"\\nVARIABLES QUE NOMÉS SURTEN AL MODEL ORIGINAL:\\n\")\n",
    "for x in nomes_original:\n",
    "    print(x)\n",
    "\n",
    "print(\"\\nVARIABLES QUE NOMÉS SURTEN AL MODEL OPTIMITZAT:\\n\")\n",
    "for x in nomes_optimitzat:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55b8ca-d004-4d9c-87a2-dc281d7b2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = gbr_opt.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "top10_features = X_train.columns[indices[:10]]\n",
    "top10_importances = importances[indices[:10]]\n",
    "\n",
    "pesos_normalitzats = top10_importances / top10_importances.sum()\n",
    "\n",
    "df_pesos = pd.DataFrame({\n",
    "    \"variable\": top10_features,\n",
    "    \"importancia\": top10_importances,\n",
    "    \"pes\": pesos_normalitzats\n",
    "}).sort_values(by=\"pes\", ascending=False)\n",
    "\n",
    "print(\"Pesos normalitzats de les top 10 variables:\")\n",
    "display(df_pesos)\n",
    "\n",
    "def calcular_score_ponderat(row):\n",
    "    return sum(row[var] * pes for var, pes in zip(top10_features, pesos_normalitzats))\n",
    "\n",
    "X_train_score = X_train[top10_features].copy()\n",
    "X_test_score = X_test[top10_features].copy()\n",
    "\n",
    "X_train_score[\"score_ponderat\"] = X_train_score.apply(calcular_score_ponderat, axis=1)\n",
    "X_test_score[\"score_ponderat\"] = X_test_score.apply(calcular_score_ponderat, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19d045-a75a-4f92-b46a-624a1270885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, gbr_opt.feature_importances_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b21df-e9b9-4ef9-a497-d9e5aa1621bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PESOS ORIGINALS DEFINITS DEL MODEL DE NEGOCI\n",
    "\n",
    "pesos_originals = {\n",
    "    \"Creations 2025\": 0.1,\n",
    "    \"Creations TOTAL\": 0.1,\n",
    "    \"NSB H1 2025\": 0.085,\n",
    "    \"NSB 24/25\": 0.085,\n",
    "    \"Priority\": 0.3,\n",
    "    \"BDO Priority\": 0.25,\n",
    "    \"Distribution Model\": 0.08\n",
    "}\n",
    "\n",
    "# 2. AGAFEM AUTOMÀTICAMENT ELS PESOS ML DEL TEU df_pesos\n",
    "\n",
    "pesos_ml_full = dict(zip(df_pesos[\"variable\"], df_pesos[\"pes\"]))\n",
    "\n",
    "# 3. CORRESPONDÈNCIES AUTOMÀTIQUES ORIGINAL ↔ ML\n",
    "\n",
    "def pes(var): \n",
    "    return pesos_ml_full.get(var, 0)\n",
    "\n",
    "pesos_ml_equivalents = {\n",
    "    \"Creations 2025\": pes(\"CREATIONS_Creations 2025\"),\n",
    "    \"Creations TOTAL\": pes(\"CREATIONS_TOTAL\"),\n",
    "    \"NSB H1 2025\": pes(\"NET SALES BILLED_NSB (H1 2025)\"),\n",
    "    \"NSB 24/25\": pes(\"NET SALES BILLED_Total Sales (24/25?)\"),\n",
    "    \"Priority\": pes(\"7 VENDORS_Priority\"),\n",
    "\n",
    "    \"BDO Priority\": (\n",
    "        pes(\"BDOs and BU SPLIT_BDOs_1.0\") +\n",
    "        pes(\"BDOs and BU SPLIT_BDOs_2.0\") +\n",
    "        pes(\"BDOs and BU SPLIT_BDOs_4.0\")\n",
    "    ),\n",
    "\n",
    "    \"Distribution Model\": sum(\n",
    "        val for key, val in pesos_ml_full.items()\n",
    "        if \"BDOs and BU SPLIT_Distribution Model\" in key\n",
    "    )\n",
    "}\n",
    "\n",
    "# 4. NORMALITZEM ELS PESOS ML PERQUÈ SUMIN 1\n",
    "\n",
    "suma = sum(pesos_ml_equivalents.values())\n",
    "pesos_ml_norm = {k: v / suma for k, v in pesos_ml_equivalents.items()}\n",
    "\n",
    "# 5. DATAFRAME COMPARATIU\n",
    "\n",
    "df_comp = pd.DataFrame({\n",
    "    \"pes_original\": pesos_originals,\n",
    "    \"pes_ml\": pesos_ml_norm\n",
    "})\n",
    "\n",
    "display(df_comp)\n",
    "\n",
    "# 6. GRÀFIC COMPARATIU\n",
    "\n",
    "df_comp.plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Comparació de pesos: Model original vs Model ML (Top 10)\")\n",
    "plt.ylabel(\"Pes normalitzat\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4784476-d7eb-4b60-b65a-d7493754fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Importàncies globals des del model ML\n",
    "llista = list(zip(X_train.columns, gbr_opt.feature_importances_))\n",
    "df_full = pd.DataFrame(llista, columns=[\"variable\", \"importancia\"])\n",
    "df_full[\"pes_global\"] = df_full[\"importancia\"] / df_full[\"importancia\"].sum()\n",
    "\n",
    "# 2) Pesos originals (ja normalitzats)\n",
    "pesos_originals = {\n",
    "    \"Creations 2025\": 0.1,\n",
    "    \"Creations TOTAL\": 0.1,\n",
    "    \"NSB H1 2025\": 0.085,\n",
    "    \"NSB 24/25\": 0.085,\n",
    "    \"Priority\": 0.3,\n",
    "    \"BDO Priority\": 0.25,\n",
    "    \"Distribution Model\": 0.08\n",
    "}\n",
    "\n",
    "# 3) Correspondències ML -> variables originals\n",
    "corresp = {\n",
    "    \"Creations 2025\": [\"CREATIONS_Creations 2025\"],\n",
    "    \"Creations TOTAL\": [\"CREATIONS_TOTAL\"],\n",
    "    \"NSB H1 2025\": [\"NET SALES BILLED_NSB (H1 2025)\"],\n",
    "    \"NSB 24/25\": [\"NET SALES BILLED_Total Sales (24/25?)\"],\n",
    "    \"Priority\": [\"7 VENDORS_Priority\"],\n",
    "    \"BDO Priority\": [\n",
    "        \"BDOs and BU SPLIT_BDOs_1.0\",\n",
    "        \"BDOs and BU SPLIT_BDOs_2.0\",\n",
    "        \"BDOs and BU SPLIT_BDOs_4.0\"\n",
    "    ],\n",
    "    \"Distribution Model\": [\n",
    "        var for var in df_full[\"variable\"]\n",
    "        if \"BDOs and BU SPLIT_Distribution Model\" in var\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 4) Pesos globals ML SUMATS per correspondència\n",
    "pesos_ml_globals_raw = {\n",
    "    nom: df_full.loc[df_full[\"variable\"].isin(vars_ml), \"pes_global\"].sum()\n",
    "    for nom, vars_ml in corresp.items()\n",
    "}\n",
    "\n",
    "# 5) Normalització correcta (només per als 7 pesos originals)\n",
    "suma_globals = sum(pesos_ml_globals_raw.values())\n",
    "pesos_ml_globals = {k: v / suma_globals for k, v in pesos_ml_globals_raw.items()}\n",
    "\n",
    "# 6) DataFrame final comparatiu\n",
    "df_global_comp = pd.DataFrame({\n",
    "    \"pes_original\": pesos_originals,\n",
    "    \"pes_ml_global\": pesos_ml_globals\n",
    "})\n",
    "\n",
    "display(df_global_comp)\n",
    "\n",
    "# 7) Gràfic comparatiu\n",
    "df_global_comp.plot(kind=\"bar\", figsize=(12,6))\n",
    "plt.title(\"Comparació de pesos: Model Original vs Pesos ML Globals (normalitzats)\")\n",
    "plt.ylabel(\"Pes normalitzat\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d54974-707e-4e8f-9fae-82b75f16e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos_originals = {\n",
    "    \"Creations 2025\": 0.1,\n",
    "    \"Creations TOTAL\": 0.1,\n",
    "    \"NSB H1 2025\": 0.085,\n",
    "    \"NSB 24/25\": 0.085,\n",
    "    \"Priority\": 0.3,\n",
    "    \"BDO Priority\": 0.25,\n",
    "    \"Distribution Model\": 0.08\n",
    "}\n",
    "\n",
    "pesos_ml_top10 = dict(zip(df_pesos[\"variable\"], df_pesos[\"pes\"]))\n",
    "def pes_top10(v): return pesos_ml_top10.get(v, 0)\n",
    "\n",
    "pesos_top10_equivalents = {\n",
    "    \"Creations 2025\": pes_top10(\"CREATIONS_Creations 2025\"),\n",
    "    \"Creations TOTAL\": pes_top10(\"CREATIONS_TOTAL\"),\n",
    "    \"NSB H1 2025\": pes_top10(\"NET SALES BILLED_NSB (H1 2025)\"),\n",
    "    \"NSB 24/25\": pes_top10(\"NET SALES BILLED_Total Sales (24/25?)\"),\n",
    "    \"Priority\": pes_top10(\"7 VENDORS_Priority\"),\n",
    "    \"BDO Priority\": (\n",
    "        pes_top10(\"BDOs and BU SPLIT_BDOs_1.0\") +\n",
    "        pes_top10(\"BDOs and BU SPLIT_BDOs_2.0\") +\n",
    "        pes_top10(\"BDOs and BU SPLIT_BDOs_4.0\")\n",
    "    ),\n",
    "    \"Distribution Model\": 0\n",
    "}\n",
    "\n",
    "s_top10 = sum(pesos_top10_equivalents.values())\n",
    "pesos_top10_norm = {k: v / s_top10 for k, v in pesos_top10_equivalents.items()}\n",
    "\n",
    "llista = list(zip(X_train.columns, gbr_opt.feature_importances_))\n",
    "df_full = pd.DataFrame(llista, columns=[\"variable\", \"importancia\"])\n",
    "df_full[\"pes_global\"] = df_full[\"importancia\"] / df_full[\"importancia\"].sum()\n",
    "\n",
    "corresp = {\n",
    "    \"Creations 2025\": [\"CREATIONS_Creations 2025\"],\n",
    "    \"Creations TOTAL\": [\"CREATIONS_TOTAL\"],\n",
    "    \"NSB H1 2025\": [\"NET SALES BILLED_NSB (H1 2025)\"],\n",
    "    \"NSB 24/25\": [\"NET SALES BILLED_Total Sales (24/25?)\"],\n",
    "    \"Priority\": [\"7 VENDORS_Priority\"],\n",
    "    \"BDO Priority\": [\n",
    "        \"BDOs and BU SPLIT_BDOs_1.0\",\n",
    "        \"BDOs and BU SPLIT_BDOs_2.0\",\n",
    "        \"BDOs and BU SPLIT_BDOs_4.0\"\n",
    "    ],\n",
    "    \"Distribution Model\": [\n",
    "        v for v in df_full[\"variable\"]\n",
    "        if \"BDOs and BU SPLIT_Distribution Model\" in v\n",
    "    ]\n",
    "}\n",
    "\n",
    "pesos_ml_global_raw = {\n",
    "    nom: df_full.loc[df_full[\"variable\"].isin(vars_ml), \"pes_global\"].sum()\n",
    "    for nom, vars_ml in corresp.items()\n",
    "}\n",
    "\n",
    "s_global = sum(pesos_ml_global_raw.values())\n",
    "pesos_ml_global = {k: v / s_global for k, v in pesos_ml_global_raw.items()}\n",
    "\n",
    "df_triple = pd.DataFrame({\n",
    "    \"Original\": pesos_originals,\n",
    "    \"Top10 ML\": pesos_top10_norm,\n",
    "    \"Global ML\": pesos_ml_global\n",
    "})\n",
    "\n",
    "display(df_triple)\n",
    "\n",
    "df_triple.plot(kind=\"bar\", figsize=(14,6))\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Pes\")\n",
    "plt.title(\"Comparació de pesos: Original vs ML Top-10 vs ML Global\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba62959-fc20-4cb8-ac7e-7139f3cf645e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
